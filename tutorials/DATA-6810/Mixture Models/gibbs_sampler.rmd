

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```


```{r gibbs_sampler, echo=FALSE}

# Gibbs sampler.


# Sample from the full conditional posterior distribution of either beta1 or beta2.
gibbs.beta <- function(index, y, z) {

  # N.B. Index specifies which mixture's beta parameter to sample (1 or 2).

  a <- 1 + 3 * sum(z == index)       # gamma distribution parameter: shape
  b <- 1 + sum(y[z == index])        # gamma distribution parameter: rate

  return(rgamma(1, shape = a, rate = b))
}


# Sample from the full conditional posterior distribution of pi1.
gibbs.pi <- function(z) {

  a <- 1 + sum(z == 1)           # beta distribution parameter: shape 1
  b <- 1 + sum(z == 2)           # beta distribution parameter: shape 2

  return(rbeta(1, shape1 = a, shape2 = b))
}


# Sample from the probability mass function of z.
gibbs.z <- function(beta1, beta2, pi, shape = 3, y) {

  # Log-probabilities are used below for numerical stability.
  # See e.g.: https://mattstats.wordpress.com/2013/04/19/numerical-stability/
  # Remember too that log(ab) = loga + logb.

  # Get the log-probabilities of observations belonging to the first mixture component.
  logp1 <- log(pi) + dgamma(y, shape = shape, rate = beta1, log = TRUE)         # dgamma; density function of the gamma distribution.
                                                                                # Setting log = TRUE returns probabilities p as log(p).
  # Get the log-probabilities of observations belonging to the second mixture component.
  logp2 <- log(1 - pi) + dgamma(y, shape = shape, rate = beta2, log = TRUE)

  # Create a two-column data structure.
  # Data in logp1 forms column 1, data in logp2 forms column 2.
  logp <- cbind(logp1, logp2)                                                   # Column bind; cbind(my_data, new_column).

  # For each row in the two-column data structure created above, shift the pair
  # of values by an amount that translates the largest value to 0. Then, perform
  # the exponential function on both values,
  #   i.e. convert log(p) to p; i.e. move from the log regime back to regular probabilities.
  p <- exp(logp - apply(logp, MARGIN = 1, max))                                 # apply; apply the max function to data in logp, by rows.

  # Normalise, below; divide each value in each pair by that pair's sum.
  #   N.B. This is done for consistency with the lecture slides.
  #        It's unnecessary however, as "sample" , automatically normalises a
  #        vector of probabilities passed to it.
  p <- p / rowSums(p)

  # For every row in p, choose a mixture designation, either "1" or "2".
  # Use the pair of row values as the probabilities of choosing each mixture designation.
  return(apply(p, MARGIN = 1, function(x) sample(c(1,2), 1, prob = x)))

}


# Implement a Gibbs sampler.
sample.mixture <- function(N, y, beta1.init, beta2.init, pi.init, z.init) {

  ##############################################################################
  # Initialisations.
  #
  # N.B. Here, N is the number of iterations to run the sampler for.

  beta1 <- rep(NA, times = N)
  beta1[1] <- beta1.init

  beta2 <- rep(NA, times = N)
  beta2[1] <- beta2.init

  pi <- rep(NA, times = N)
  pi[1] <- pi.init

  # Each matrix column stores values applicable to a Gibbs sampler iteration.
  # I.e. iteration 1 fills column 1, iteration 2 fills column 2, etc.
  z <- matrix(NA, nrow = length(y), ncol = N)
  z[,1] <- z.init
  ##############################################################################

  
  # Gibbs sampling
  #   For each parameter, draw a sample conditioned on the value of other
  #   relevant parameters.
  #
  for (i in 2:N) {
    
    # Sample beta1[i] ~ f(beta1 | z[i-1], y)
    beta1[i] <- gibbs.beta(index = 1, y, z[,i - 1])

    # Sample beta2[i] ~ f(beta2 | z[i-1], y)
    beta2[i] <- gibbs.beta(index = 2, y, z[,i - 1])

    # Sample pi[i] ~ f(pi | z[i-1])
    pi[i] <- gibbs.pi(z[,i - 1])

    # Sample z[i] ~ f(z | beta1[i], beta2[i], pi[i], y)
    z[,i] <- gibbs.z(beta1[i], beta2[i], pi[i], shape = 3, y)
  }

  return(list(beta1 = beta1, beta2 = beta2, pi = pi, z = z))
}

```


```{r gibbs_tester, echo=FALSE}

# Load data for a mixture of two gamma distributions.
load("~/Desktop/DARE/DARE-PhD/tutorials/DATA-6810/Mixture Models/gamma_mixture.Rdata")

# Configure plotting options.
par(mfrow = c(2, 3))

# When calling the sampler...
#
# a) the exact values used to initialise beta1 and beta2
#    (i.e. beta1.init and beta2.init) aren't important, as long as they're > 0;
#    gamma distributions can't have a shape or rate parameters <= 0.
#
# b) the value used to initialise pi should conform to the constraints of a
#    mixture weight, i.e. > 0 and <= 1.
#
result1 <- sample.mixture(N = 20000, y = dataset1,
  pi.init = 0.5, beta1.init = 0.5, beta2.init = 1,
  z.init = sample(c(1,2), size = length(dataset1), replace = TRUE, prob = c(0.5, 0.5)))

plot(1:20000, result1$beta1, "l", main = "dataset1", xlab = "Iteration", ylab = expression(beta[1]))
lines(1:20000, cumsum(result1$beta1) / 1:20000, col = "red")

plot(1:20000, result1$beta2, "l", xlab = "Iteration", ylab = expression(beta[2]))
lines(1:20000, cumsum(result1$beta2) / 1:20000, col = "red")

plot(1:20000, result1$pi, "l", xlab = "Iteration", ylab = expression(pi[1]))
lines(1:20000, cumsum(result1$pi) / 1:20000, col = "red")


result2 <- sample.mixture(N = 20000, y = dataset2,
  pi.init = 0.5, beta1.init = 0.5, beta2.init = 1,
  z.init = sample(c(1,2), size = length(dataset2), replace = TRUE, prob = c(0.5, 0.5)))

plot(1:20000, result2$beta1, "l", main = "dataset2", xlab = "Iteration", ylab = expression(beta[1]))
lines(1:20000, cumsum(result2$beta1) / 1:20000, col = "red")

plot(1:20000, result2$beta2, "l", xlab = "Iteration", ylab = expression(beta[2]))
lines(1:20000, cumsum(result2$beta2) / 1:20000, col = "red")

plot(1:20000, result2$pi, "l", xlab = "Iteration", ylab = expression(pi[1]))
lines(1:20000, cumsum(result2$pi) / 1:20000, col = "red")

```


```{r mc_estimation_dense_grid, echo=FALSE}

# Configure plotting options.
par(mfrow = c(2, 4))


# Plot the mixture from dataset1.
hx1 <- matrix(NA, nrow = 201, ncol = 20000)
for (i in 1:20000) {
  hx1[,i] <- result1$pi[i] * dgamma(seq(0, 20, by = 0.1), shape = 3, rate = result1$beta1[i]) +
             (1 - result1$pi[i]) * dgamma(seq(0, 20, by = 0.1), shape = 3, rate = result1$beta2[i])
}
# Trace plots of h(x) for dataset1.
# Try at x = 0, 5, 10.
plot(1:20000, hx1[1,], main = "dataset1", xlab = "Iteration", ylab = "h(x), x = 0", "l")   # Use "l" for a line plot.
plot(1:20000, hx1[51,], main = "dataset1", xlab = "Iteration", ylab = "h(x), x = 5", "l")
plot(1:20000, hx1[101,], main = "dataset1", xlab = "Iteration", ylab = "h(x), x = 10", "l")
#
# Estimated density plot of h for dataset1.
plot(seq(0, 20, by = 0.1), apply(hx1, MARGIN = 1, mean), main = "dataset1", xlab = "x", ylab = "density", "l")   # apply; apply the mean function to hx1, by rows.


# Plot the mixture from dataset2.
hx2 <- matrix(NA, nrow = 201, ncol = 20000)
for (i in 1:20000) {
  hx2[,i] <- result2$pi[i] * dgamma(seq(0, 20, by = 0.1), shape = 3, rate = result2$beta1[i]) +
             (1 - result2$pi[i]) * dgamma(seq(0, 20, by = 0.1), shape = 3, rate = result2$beta2[i])
}
# Trace plots of h(x) for dataset2.
# Try at x = 0, 5, 10.
plot(1:20000, hx2[1,], main = "dataset2", xlab = "Iteration", ylab = "h(x), x = 0", "l")   # Use "l" for a line plot.
plot(1:20000, hx2[51,], main = "dataset2", xlab = "Iteration", ylab = "h(x), x = 5", "l")   # Use "l" for a line plot.
plot(1:20000, hx2[101,], main = "dataset2", xlab = "Iteration", ylab = "h(x), x = 10", "l")
# Estimated density plot of h for dataset2.
plot(seq(0, 20, by = 0.1), apply(hx2, MARGIN = 1, mean), main = "dataset2", xlab = "x", ylab = "density", "l")   # apply; apply the max function to hx2, by rows.

```
